{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkExpansionPy.lib as ne\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolism = ne.GlobalMetabolicNetwork()\n",
    "#metabolism.pruneUnbalancedReactions()\n",
    "metabolism.pruneInconsistentReactions()\n",
    "#metabolism.set_ph(7.0)\n",
    "metabolism.convertToIrreversible()\n",
    "#metabolism.setMetaboliteBounds(ub=1e-1,lb=1e-6)\n",
    "#metabolism.pruneThermodynamicallyInfeasibleReactions(keepnan=False)\n",
    "\n",
    "# construct params for network expansion\n",
    "network = metabolism.network.pivot_table(index='cid',columns = ['rn','direction'],values='s').fillna(0)\n",
    "S = network.values\n",
    "R = (S < 0)*1\n",
    "P = (S > 0)*1\n",
    "b = sum(R)\n",
    "\n",
    "# sparsefy data\n",
    "R = csr_matrix(R)\n",
    "P = csr_matrix(P)\n",
    "b = csr_matrix(b)\n",
    "b = b.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_index = pd.DataFrame(list(network),columns = ['rn','direction']).groupby('rn').min()[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuagoldford/miniconda2/envs/network_expansion/lib/python3.6/site-packages/scipy/sparse/compressed.py:226: SparseEfficiencyWarning: Comparing sparse matrices using == is inefficient, try using != instead.\n",
      "  \" != instead.\", SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "fixed_metabolites = ['C00001','C00011','C00080','C00014','C00009','C00283']\n",
    "seedSet = fixed_metabolites\n",
    "x0 = np.array([x in seedSet for x in network.index.get_level_values(0)]) * 1\n",
    "x0 = csr_matrix(x0)\n",
    "x0 = x0.transpose()\n",
    "met_trace,reaction_trace = ne.netExp_trace(R,P,x0,b)\n",
    "rxn_iter = ne.parse_reaction_trace(reaction_trace,network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_iter.to_csv('6seedReactionIter.Nov2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuagoldford/miniconda2/envs/network_expansion/lib/python3.6/site-packages/scipy/sparse/compressed.py:226: SparseEfficiencyWarning: Comparing sparse matrices using == is inefficient, try using != instead.\n",
      "  \" != instead.\", SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with 0 iteration and saved df\n",
      "finished with 100 iteration and saved df\n",
      "finished with 200 iteration and saved df\n",
      "finished with 300 iteration and saved df\n",
      "finished with 400 iteration and saved df\n",
      "finished with 500 iteration and saved df\n",
      "finished with 600 iteration and saved df\n",
      "finished with 700 iteration and saved df\n",
      "finished with 800 iteration and saved df\n",
      "finished with 900 iteration and saved df\n",
      "finished with 1000 iteration and saved df\n",
      "finished with 1100 iteration and saved df\n",
      "finished with 1200 iteration and saved df\n",
      "finished with 1300 iteration and saved df\n",
      "finished with 1400 iteration and saved df\n",
      "finished with 1500 iteration and saved df\n",
      "finished with 1600 iteration and saved df\n",
      "finished with 1700 iteration and saved df\n",
      "finished with 1800 iteration and saved df\n",
      "finished with 1900 iteration and saved df\n",
      "finished with 2000 iteration and saved df\n",
      "finished with 2100 iteration and saved df\n",
      "finished with 2200 iteration and saved df\n",
      "finished with 2300 iteration and saved df\n",
      "finished with 2400 iteration and saved df\n",
      "finished with 2500 iteration and saved df\n",
      "finished with 2600 iteration and saved df\n",
      "finished with 2700 iteration and saved df\n",
      "finished with 2800 iteration and saved df\n",
      "finished with 2900 iteration and saved df\n",
      "finished with 3000 iteration and saved df\n",
      "finished with 3100 iteration and saved df\n",
      "finished with 3200 iteration and saved df\n",
      "finished with 3300 iteration and saved df\n",
      "finished with 3400 iteration and saved df\n",
      "finished with 3500 iteration and saved df\n",
      "finished with 3600 iteration and saved df\n",
      "finished with 3700 iteration and saved df\n",
      "finished with 3800 iteration and saved df\n",
      "finished with 3900 iteration and saved df\n",
      "finished with 4000 iteration and saved df\n",
      "finished with 4100 iteration and saved df\n",
      "finished with 4200 iteration and saved df\n",
      "finished with 4300 iteration and saved df\n",
      "finished with 4400 iteration and saved df\n",
      "finished with 4500 iteration and saved df\n",
      "finished with 4600 iteration and saved df\n",
      "finished with 4700 iteration and saved df\n",
      "finished with 4800 iteration and saved df\n",
      "finished with 4900 iteration and saved df\n",
      "finished with 5000 iteration and saved df\n",
      "finished with 5100 iteration and saved df\n",
      "finished with 5200 iteration and saved df\n",
      "finished with 5300 iteration and saved df\n",
      "finished with 5400 iteration and saved df\n",
      "finished with 5500 iteration and saved df\n",
      "finished with 5600 iteration and saved df\n",
      "finished with 5700 iteration and saved df\n",
      "finished with 5800 iteration and saved df\n",
      "finished with 5900 iteration and saved df\n",
      "finished with 6000 iteration and saved df\n",
      "finished with 6100 iteration and saved df\n",
      "finished with 6200 iteration and saved df\n",
      "finished with 6300 iteration and saved df\n",
      "finished with 6400 iteration and saved df\n",
      "finished with 6500 iteration and saved df\n",
      "finished with 6600 iteration and saved df\n",
      "finished with 6700 iteration and saved df\n",
      "finished with 6800 iteration and saved df\n",
      "finished with 6900 iteration and saved df\n",
      "finished with 7000 iteration and saved df\n",
      "finished with 7100 iteration and saved df\n",
      "finished with 7200 iteration and saved df\n",
      "finished with 7300 iteration and saved df\n",
      "finished with 7400 iteration and saved df\n",
      "finished with 7500 iteration and saved df\n",
      "finished with 7600 iteration and saved df\n",
      "finished with 7700 iteration and saved df\n",
      "finished with 7800 iteration and saved df\n",
      "finished with 7900 iteration and saved df\n",
      "finished with 8000 iteration and saved df\n",
      "finished with 8100 iteration and saved df\n",
      "finished with 8200 iteration and saved df\n",
      "finished with 8300 iteration and saved df\n",
      "finished with 8400 iteration and saved df\n",
      "finished with 8500 iteration and saved df\n",
      "finished with 8600 iteration and saved df\n",
      "finished with 8700 iteration and saved df\n",
      "finished with 8800 iteration and saved df\n",
      "finished with 8900 iteration and saved df\n",
      "finished with 9000 iteration and saved df\n",
      "finished with 9100 iteration and saved df\n",
      "finished with 9200 iteration and saved df\n",
      "finished with 9300 iteration and saved df\n",
      "finished with 9400 iteration and saved df\n",
      "finished with 9500 iteration and saved df\n",
      "finished with 9600 iteration and saved df\n",
      "finished with 9700 iteration and saved df\n",
      "finished with 9800 iteration and saved df\n",
      "finished with 9900 iteration and saved df\n"
     ]
    }
   ],
   "source": [
    "\n",
    "size_of_random_sample = 6\n",
    "fixed_metabolites = ['C00001','C00011','C00080','C00014','C00009','C00283']\n",
    "mets_population = [x for x in network.index.get_level_values(0).tolist() if x not in fixed_metabolites]\n",
    "\n",
    "numSims = 10000;\n",
    "sims = []\n",
    "\n",
    "df = rn_index.copy()\n",
    "\n",
    "# define iterations to save dataframe:\n",
    "saveIter = np.linspace(0,numSims,101)\n",
    "\n",
    "for i in range(numSims):\n",
    "    \n",
    "    seedSet = sample(mets_population,size_of_random_sample) + fixed_metabolites\n",
    "    x0 = np.array([x in seedSet for x in network.index.get_level_values(0)]) * 1\n",
    "    x0 = csr_matrix(x0)\n",
    "    x0 = x0.transpose()\n",
    "    met_trace,reaction_trace = ne.netExp_trace(R,P,x0,b)\n",
    "    rxn_iter = ne.parse_reaction_trace(reaction_trace,network)\n",
    "    sim = rxn_iter.groupby('rn').min()['iter']\n",
    "    sim = pd.DataFrame(sim)\n",
    "    sim.columns = [i]\n",
    "    df = df.join(sim)\n",
    "    #save simulations\n",
    "    if i in saveIter:\n",
    "        df.to_hdf('ne_results.12seedSet.ConsistentNetwork.11222020.temp.hdf','df')\n",
    "        print('finished with ' + str(i)  + ' iteration and saved df')\n",
    "    \n",
    "\n",
    "df.to_hdf('ne_results.12seedSet.ConsistentNetwork.11222020.hdf','df')\n",
    "#sims = pd.concat(sims,axis=1)\n",
    "#sims.to_csv('randNetworkExpansion.Full.CHOSNPfixedMets.1e4samples.6mets.11202020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df\n",
    "df.to_hdf('ne_results.12seedSet.ConsistentNetwork.11222020.final.hdf','df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleNumToCount = {'rn':[],'cycle':[],'count':[]}\n",
    "for i in range(1,80):\n",
    "    for rxn in rxns:\n",
    "        numOccur = sum(df[rxn] == i)\n",
    "        cycleNumToCount['rn'].append(rxn)\n",
    "        cycleNumToCount['cycle'].append(i)\n",
    "        cycleNumToCount['count'].append(numOccur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleNumToCount = pd.DataFrame(cycleNumToCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleNumToCount.to_csv('ne_results.12seedSet.ConsistentNetwork.11222020.cycleCount.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = cycleNumToCount.pivot_table(index='cycle',columns='rn',values='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = cn / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (network_expansion3)",
   "language": "python",
   "name": "network_expansion3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
